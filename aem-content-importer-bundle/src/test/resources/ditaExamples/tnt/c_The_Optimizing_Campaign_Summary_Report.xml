<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd"[]>
<concept id="concept_EB9B6BAF93694AEA8126F54E3DBDDD19" xmlns:ditaarch="http://dita.oasis-open.org/architecture/2005/" ditaarch:DITAArchVersion="1.1" domains="(topic ui-d) (topic hi-d) (topic pr-d) (topic sw-d)                          (topic ut-d) (topic indexing-d)" class="- topic/topic concept/concept ">
  <title class="- topic/title ">The Optimizing Campaign Summary Report</title>
  <shortdesc class="- topic/shortdesc ">The Optimizing Campaign summary report
	 compares campaign performance with random traffic (labeled Testing Traffic in
	 the report). 
  </shortdesc>
  <prolog>
    <metadata>
      <othermeta name="solution" content="Target" />
      <othermeta name="topic" content="Advanced" />
    </metadata>
  </prolog>
  <conbody class="- topic/body  concept/conbody ">
    <p class="- topic/p ">The comparison allows you to ask the question: 
		<i class="+ topic/ph hi-d/i ">Is my self-optimizing campaign performing
		  better or worse than if I served my experiences evenly?</i></p>
    <p class="- topic/p ">
      <i class="+ topic/ph hi-d/i ">Testing Traffic</i> refers to the visits
		whose experiences are served randomly, rather than through rules generated by
		the algorithm. By serving roughly 10% of total traffic as Testing Traffic, the
		algorithm can measure campaign performance. Because the optimizing campaign is
		visit-based, it's important to choose "Visit" as the counting methodology. The
		comparison column should reflect the success metric chosen when defining the
		campaign. 
	 </p>
    <p class="- topic/p ">
      <i class="+ topic/ph hi-d/i ">Segment Targeted</i> refers to the visits
		whose experiences are served through rules generated by the algorithm. The
		summary report also displays lift and confidence for this traffic. 
	 </p>
    <p class="- topic/p ">Because the optimizing campaign is visit-based, it's
		important to choose "Visit" as the counting methodology. The key success metric
		should reflect the success metric chosen when defining the campaign. 
	 </p>
    <p class="- topic/p ">
      <b class="+ topic/ph hi-d/b ">Advanced Reporting</b>
    </p>
    <p class="- topic/p ">Although the primary emphasis should be overall
		campaign performance versus the control experience, the campaign row can be
		expanded for greater insight into the campaign traffic. 
	 </p>
    <p class="- topic/p ">Both the 
		<i class="+ topic/ph hi-d/i ">Testing Traffic</i> and 
		<i class="+ topic/ph hi-d/i ">Segment Targeted</i> rows can be further
		expanded to view the number of visits and conversions for their component
		experiences. Lift and confidence is only displayed for the aggregated sections.
		
	 </p>
  </conbody>
  <related-links class="- topic/related-links ">
    <link href="c_The_Optimizing_Campaign_Insights_Report.xml#concept_E7A41035120E4927887EA461B9A8FE60" type="concept" format="dita" scope="local" class="- topic/link ">
      <?xm-replace_text The Optimizing Campaign Insights Report?>
    </link>
  </related-links>
</concept>